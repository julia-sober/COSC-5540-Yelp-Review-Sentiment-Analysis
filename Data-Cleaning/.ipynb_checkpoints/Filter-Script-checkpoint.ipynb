{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad214fd-7e90-4ff9-b254-915b714b3a48",
   "metadata": {},
   "source": [
    "# Yelp Data Filter Script\n",
    "\n",
    "This script processes the full Yelp dataset JSON files and produces filtered CSVs \n",
    "containing only data relevant to restaurant reviews. Specifically, it:\n",
    "\n",
    "1. Loads `business.json` and filters businesses to only those in restaurant-related categories.\n",
    "2. Filters `review.json`, `checkin.json`, and `tip.json` to include only entries \n",
    "   associated with the filtered restaurants.\n",
    "3. Filters `user.json` to include only users who wrote reviews in the filtered review dataset.\n",
    "4. Saves all filtered datasets to CSV for easier analysis.\n",
    "\n",
    "The script is designed to handle large datasets efficiently using chunked processing \n",
    "to avoid excessive memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4e027ba-2820-4024-95d4-f6e846cdff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66050131-05d6-4467-82ac-ebba555f3485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all of the businesses \n",
    "file = \"full-dataset/yelp_academic_dataset_business.json\"\n",
    "df = pd.read_json(file, lines=True) # lines = true b/c each line in the file is its own JSON object\n",
    "\n",
    "# Filter out only the restaurants by keyword\n",
    "keywords = [\"Restaurants\", \"Food\", \"Cafes\", \"Coffee & Tea\", \"Bakeries\", \"Bars\", \"Fast Food\", \"Pizza\", \"Sandwiches\", \"Breakfast & Brunch\"]\n",
    "pattern = \"|\".join(keywords)\n",
    "\n",
    "# Saving this dataframe so I can use business_id to cross-reference with other dataframes\n",
    "# Note: could use similar logic to filter by city as well\n",
    "df_restaurants = df[df['categories'].str.contains(pattern, case=False, na=False)]\n",
    "restaurant_ids = df_restaurants[\"business_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eecd638-da34-4fd1-9961-51bd9a5a56ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will load a Yelp JSON dataset in chunks (rather than all at once) and filter by restaurant business_ids \n",
    "# (which we've already identified)\n",
    "def filter_datasets_chunked(filename, chunksize=100000):\n",
    "    filtered_chunks = []\n",
    "    for chunk in pd.read_json(filename, lines=True, chunksize=chunksize):\n",
    "        filtered = chunk[chunk[\"business_id\"].isin(restaurant_ids)]\n",
    "        filtered_chunks.append(filtered)\n",
    "    \n",
    "    return pd.concat(filtered_chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "459e5de0-54a7-44e9-9455-39831cdac368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out all non-restaurant data from other datasets\n",
    "filtered_checkin = filter_datasets_chunked(\"full-dataset/yelp_academic_dataset_checkin.json\")\n",
    "filtered_review = filter_datasets_chunked(\"full-dataset/yelp_academic_dataset_review.json\")\n",
    "filtered_tip = filter_datasets_chunked(\"full-dataset/yelp_academic_dataset_tip.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3969f080-5cbd-4e18-93bb-e796d3d8c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I am going to do the same thing for the users dataset (getting data only from users who reviewed one \n",
    "# of the restaurants we have reviews for)\n",
    "user_ids = filtered_review[\"user_id\"].unique()\n",
    "filename = \"full-dataset/yelp_academic_dataset_user.json\"\n",
    "filtered_chunks = []\n",
    "for chunk in pd.read_json(filename, lines=True, chunksize=100000):\n",
    "    filtered = chunk[chunk[\"user_id\"].isin(user_ids)]\n",
    "    filtered_chunks.append(filtered)\n",
    "    \n",
    "filtered_user = pd.concat(filtered_chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f42bc304-b7dd-499b-9fb4-68626665f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving all of these datasets in csv format\n",
    "df_restaurants.to_csv(\"data-restaurants-only/business.csv\", index=False)\n",
    "filtered_checkin.to_csv(\"data-restaurants-only/checkin.csv\", index=False)\n",
    "filtered_review.to_csv(\"data-restaurants-only/review.csv\", index=False)\n",
    "filtered_tip.to_csv(\"data-restaurants-only/tip.csv\", index=False)\n",
    "filtered_user.to_csv(\"data-restaurants-only/user.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
