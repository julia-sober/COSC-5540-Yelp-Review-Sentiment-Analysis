{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fd89919-f4c9-40cb-8d44-2eed4ebc6509",
   "metadata": {},
   "source": [
    "# Yelp Data Association Script (State-Split Version)\n",
    "\n",
    "This script merges all filtered Yelp datasets and produces **smaller, state-specific DataFrames** for analysis. \n",
    "Each dataset's columns are prefixed to indicate their source:\n",
    "\n",
    "- `review_` → review information  \n",
    "- `business_` → business information  \n",
    "- `checkin_` → checkin summary  \n",
    "- `tip_` → tip summary  \n",
    "- `user_` → user information  \n",
    "\n",
    "### Key Steps\n",
    "\n",
    "1. **Rename columns** in each dataset (except merge keys) to indicate their source.  \n",
    "2. **Aggregate** checkins (`total_checkins`) and tips (`num_tips`) to avoid row duplication.  \n",
    "3. **Merge** reviews with business info, checkins, tips, and user info using `business_id` and `user_id`.  \n",
    "4. **Split by state**: the resulting DataFrame is broken into smaller DataFrames for each `business_state`.  \n",
    "5. Each state-specific DataFrame is saved separately (CSV), making it easier to work with large datasets.\n",
    "\n",
    "> **Note:** Column prefixes ensure that the origin of each field is clear. Splitting by state allows analysis without memory issues caused by a single huge DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4b5873c-8e96-4e4e-b173-f417f046d148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef0f1dca-6486-4008-b4c0-dd6fd7315747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cl/5mfvhcls2nv2h9gy15m04b640000gn/T/ipykernel_37414/2635155766.py:6: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  user_df = pd.read_csv(\"data-restaurants-only/user.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Load all filtered datasets\n",
    "business_df = pd.read_csv(\"data-restaurants-only/business.csv\")\n",
    "checkin_df = pd.read_csv(\"data-restaurants-only/checkin.csv\")\n",
    "review_df = pd.read_csv(\"data-restaurants-only/review.csv\")\n",
    "tip_df = pd.read_csv(\"data-restaurants-only/tip.csv\")\n",
    "user_df = pd.read_csv(\"data-restaurants-only/user.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21729453-c8d2-4ece-81e0-15f9732817e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep dataframes for merging:\n",
    "# 1. Rename columns to include suffix for source dataframe\n",
    "# 2. and aggregate tip/checkin data into useful format\n",
    "\n",
    "review_df_renamed = review_df.rename(\n",
    "    columns={col: f\"review_{col}\" for col in review_df.columns if col not in ['review_id', 'business_id', 'user_id']}\n",
    ")\n",
    "\n",
    "business_df_renamed = business_df.rename(\n",
    "    columns={col: f\"business_{col}\" for col in business_df.columns if col != 'business_id'}\n",
    ")\n",
    "\n",
    "user_df_renamed = user_df.rename(\n",
    "    columns={col: f\"user_{col}\" for col in user_df.columns if col != 'user_id'}\n",
    ")\n",
    "\n",
    "# I am aggregating to total_checkins b/c I think that is the only useful feature I could possibly extract\n",
    "# I don't necessarily think this will be useful but I am not getting rid of any data at this stage\n",
    "checkin_df['total_checkins'] = checkin_df['date'].str.count(',')\n",
    "checkin_summary = checkin_df[['business_id', 'total_checkins']].rename(\n",
    "    columns={'total_checkins': 'checkin_total_checkins'}\n",
    ")\n",
    "\n",
    "# Aggregating tip data: count number of tips per business\n",
    "tips_summary = tip_df.groupby('business_id').agg({\n",
    "    'user_id': 'count'  # number of tips\n",
    "}).rename(columns={'user_id': 'tip_num_tips'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4caac1ed-dc1b-4478-a323-ccbd24519030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging all of the data into one associated dataframe\n",
    "\n",
    "# Start by merging reviews with business info\n",
    "df = review_df_renamed.merge(business_df_renamed, on='business_id', how='left')\n",
    "\n",
    "# Merge checkin summary data\n",
    "df = df.merge(checkin_summary, on='business_id', how='left')\n",
    "\n",
    "# Merge tip summary data\n",
    "df = df.merge(tips_summary, on='business_id', how='left')\n",
    "\n",
    "# Finally merge with the user data\n",
    "df = df.merge(user_df_renamed, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6e1bf3b-0337-4962-bacf-d2872db774e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>review_useful</th>\n",
       "      <th>review_funny</th>\n",
       "      <th>review_cool</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_date</th>\n",
       "      <th>business_name</th>\n",
       "      <th>...</th>\n",
       "      <th>user_compliment_more</th>\n",
       "      <th>user_compliment_profile</th>\n",
       "      <th>user_compliment_cute</th>\n",
       "      <th>user_compliment_list</th>\n",
       "      <th>user_compliment_note</th>\n",
       "      <th>user_compliment_plain</th>\n",
       "      <th>user_compliment_cool</th>\n",
       "      <th>user_compliment_funny</th>\n",
       "      <th>user_compliment_writer</th>\n",
       "      <th>user_compliment_photos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "      <td>Turning Point of North Wales</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saUsX_uimxRlCVr67Z4Jig</td>\n",
       "      <td>8g_iMtfSiwikVnbP2etR0A</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n",
       "      <td>2014-02-05 20:30:30</td>\n",
       "      <td>Kettle Restaurant</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "      <td>Zaika</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sx8TMOWLNuJBWer-0pcmoA</td>\n",
       "      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>2017-01-14 20:54:15</td>\n",
       "      <td>Melt</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JrIxlS1TzJ-iCu79ul40cQ</td>\n",
       "      <td>eUta8W_HdHMXPzLBBZhL1A</td>\n",
       "      <td>04UD14gamNjLY0IDYVhHJg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I am a long term frequent customer of this est...</td>\n",
       "      <td>2015-09-23 23:10:31</td>\n",
       "      <td>Dmitri's</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "1  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n",
       "2  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "3  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n",
       "4  JrIxlS1TzJ-iCu79ul40cQ  eUta8W_HdHMXPzLBBZhL1A  04UD14gamNjLY0IDYVhHJg   \n",
       "\n",
       "   review_stars  review_useful  review_funny  review_cool  \\\n",
       "0           3.0            0.0           0.0          0.0   \n",
       "1           3.0            0.0           0.0          0.0   \n",
       "2           5.0            1.0           0.0          1.0   \n",
       "3           4.0            1.0           0.0          1.0   \n",
       "4           1.0            1.0           2.0          1.0   \n",
       "\n",
       "                                         review_text          review_date  \\\n",
       "0  If you decide to eat here, just be aware it is...  2018-07-07 22:09:11   \n",
       "1  Family diner. Had the buffet. Eclectic assortm...  2014-02-05 20:30:30   \n",
       "2  Wow!  Yummy, different,  delicious.   Our favo...  2015-01-04 00:01:03   \n",
       "3  Cute interior and owner (?) gave us tour of up...  2017-01-14 20:54:15   \n",
       "4  I am a long term frequent customer of this est...  2015-09-23 23:10:31   \n",
       "\n",
       "                  business_name  ... user_compliment_more  \\\n",
       "0  Turning Point of North Wales  ...                  0.0   \n",
       "1             Kettle Restaurant  ...                 14.0   \n",
       "2                         Zaika  ...                  1.0   \n",
       "3                          Melt  ...                  0.0   \n",
       "4                      Dmitri's  ...                  0.0   \n",
       "\n",
       "  user_compliment_profile user_compliment_cute user_compliment_list  \\\n",
       "0                     0.0                  0.0                  0.0   \n",
       "1                     3.0                  1.0                  1.0   \n",
       "2                     0.0                  0.0                  0.0   \n",
       "3                     0.0                  0.0                  0.0   \n",
       "4                     0.0                  0.0                  0.0   \n",
       "\n",
       "   user_compliment_note  user_compliment_plain  user_compliment_cool  \\\n",
       "0                   0.0                    0.0                   1.0   \n",
       "1                  63.0                   96.0                  86.0   \n",
       "2                   0.0                    0.0                   0.0   \n",
       "3                   0.0                    1.0                   0.0   \n",
       "4                   1.0                    0.0                   0.0   \n",
       "\n",
       "   user_compliment_funny  user_compliment_writer user_compliment_photos  \n",
       "0                    1.0                     0.0                    0.0  \n",
       "1                   86.0                    49.0                   27.0  \n",
       "2                    0.0                     0.0                    0.0  \n",
       "3                    0.0                     2.0                    1.0  \n",
       "4                    0.0                     0.0                    0.0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have one big associated dataframe ready for modeling!!\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1a4019c-35f9-4739-baeb-183cf4bd32b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:  associated-data-by-state/consolidated_PA.csv\n",
      "Saved:  associated-data-by-state/consolidated_AZ.csv\n",
      "Saved:  associated-data-by-state/consolidated_LA.csv\n",
      "Saved:  associated-data-by-state/consolidated_CA.csv\n",
      "Saved:  associated-data-by-state/consolidated_IN.csv\n",
      "Saved:  associated-data-by-state/consolidated_MO.csv\n",
      "Saved:  associated-data-by-state/consolidated_FL.csv\n",
      "Saved:  associated-data-by-state/consolidated_TN.csv\n",
      "Saved:  associated-data-by-state/consolidated_NV.csv\n",
      "Saved:  associated-data-by-state/consolidated_NJ.csv\n",
      "Saved:  associated-data-by-state/consolidated_IL.csv\n",
      "Saved:  associated-data-by-state/consolidated_ID.csv\n",
      "Saved:  associated-data-by-state/consolidated_AB.csv\n",
      "Saved:  associated-data-by-state/consolidated_DE.csv\n",
      "Saved:  associated-data-by-state/consolidated_HI.csv\n",
      "Saved:  associated-data-by-state/consolidated_NC.csv\n",
      "Saved:  associated-data-by-state/consolidated_CO.csv\n",
      "Saved:  associated-data-by-state/consolidated_MT.csv\n",
      "Saved:  associated-data-by-state/consolidated_nan.csv\n",
      "Saved:  associated-data-by-state/consolidated_XMS.csv\n"
     ]
    }
   ],
   "source": [
    "# Saving this huge dataframe to csv leads to a memory bottleneck\n",
    "# So I am instead going to break it up by state (location)\n",
    "states = df.business_state.unique()\n",
    "for state in states:\n",
    "    df_state = df[df['business_state'] == state].copy()\n",
    "    filename = f\"associated-data-by-state/consolidated_{state}.csv\"\n",
    "    df_state.to_csv(filename, index=False)\n",
    "    print(\"Saved: \", filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
